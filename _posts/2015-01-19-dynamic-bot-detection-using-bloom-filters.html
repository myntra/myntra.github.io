---
layout: post
title: Dynamic Bot Detection Using Bloom Filters
---

<div dir="ltr" style="text-align: left;" trbidi="on"><h4 style="text-align: left;">Problem at hand</h4><div>Bots or crawl programs are a fact of life for any property accessible on the web, be it a blog, an e-commerce website, a media website or a company website. There may be varied crawling motives ranging from search engines to competitors to internal test suites to rookie programmers. These bots can be either classified as "good bots" who explicitly announce their visit and there are "not so good bots" who choose to mask themselves. These category of "not so good bots" meddle up with the analytics tasks at hand because of them getting wrongly categorised as genuine users.<br /><br /><h4 style="text-align: left;">Any pattern to leverage?</h4></div><div>Bots are usually in a hurry to crawl the website and issue page requests at a far higher frequency than humanly possible. This property can be effectively leveraged to find whether the website activity is done by a bot or a human.</div><div><br /></div><h4 style="text-align: left;">Solution design - bloom filters</h4><div>Bloom filters are an efficient way to find rapidly and memory-efficiently, whether an element is present in a set. The solution design is simply around maintaining a bloom filter for every second of the day and putting the web request signature (request ip address&nbsp;+ request user agent) into it for every incoming web request. After putting this entry, check for the same signature's existence in the last 60 seconds buckets, which is an efficient task and can be done in real-time for all incoming requests due to the speed guarantees that bloom filter provides. In case this is a bot there would be very high chances of finding the same signature in majority of the past 60 buckets. We can now choose a policy of counting such "offences" and put a threshold above which the signature would be blacklisted and all related activities filtered.</div><h4 style="text-align: left;"><br /></h4><h4 style="text-align: left;">Results</h4><div>We have been able to find and classify around 5% of total events received as bots which would have otherwise sneaked in.</div></div>
